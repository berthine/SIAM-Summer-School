{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SIAM2021 Image Classification 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berthine/SIAM-Summer-School/blob/main/Copy_of_SIAM2021_Image_Classification_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs3Vxo5dmP7j"
      },
      "source": [
        "## Practical: Image classification\n",
        "(20/July/2021)\n",
        "\n",
        "### 2021 Gene Golub SIAM Summer School \n",
        "https://sites.google.com/aims.ac.za/g2s3/home \n",
        "\n",
        "Instructor\n",
        "\n",
        "<font color=\"green\">***Dr. Emmanuel Dufourq*** \n",
        "\n",
        "www.emmanueldufourq.com\n",
        "\n",
        "edufourq (['@']) gmail.com\n",
        "\n",
        "***African Institute for Mathematical Sciences***\n",
        "\n",
        "***Stellenbosch University***\n",
        "\n",
        "***2021***\n",
        "\n",
        "<br>\n",
        "\n",
        "***NOTE***\n",
        "\n",
        "<font color=\"red\">**Be sure to use hardware acceleration to use the GPU. Click on `Runtime`, change `runtime type`, and select `GPU` for the *hardware accelerator* option. Try to limit your time with the GPU. Terminate the session when possible due to limitations.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W--Tn2TNfUQc"
      },
      "source": [
        "## <font color=\"green\"> Learning outcomes:\n",
        "\n",
        "* learn how implement CNNs\n",
        "\n",
        "* learn about ```Conv2D, MaxPool2D, Flatten, Dropout```\n",
        "\n",
        "* learn how to implement ```ModelCheckpoint``` and view them in the file system\n",
        "\n",
        "* learn how to convert softmax output into class predictions\n",
        "\n",
        "## <font color=\"green\">Data information:\n",
        "\n",
        "* Features: (28x28) images\n",
        "\n",
        "* Output: 10 classes represented by integers\n",
        "\n",
        "## <font color=\"green\">Tasks for participants (boolean)?\n",
        "\n",
        "* Yes, at the end (try avoid copy/pasting code, rather write it out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpvo-bqTmP7m"
      },
      "source": [
        "## Imports first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvCXvXq5mP7p"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, AveragePooling2D\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GTR35cmP7v"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "We will use the FashionMNIST dataset. Documentation https://www.tensorflow.org/datasets/catalog/fashion_mnist\n",
        "\n",
        "By the way, there are a ton of datasets already available to you from Tensorflow, check them out here: https://www.tensorflow.org/datasets/catalog/overview\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Note that the data has already been split into training and testing for us, phew! What's next though?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_KjFJomP7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232263dc-4847-4a34-8bb0-c3e2018224ee"
      },
      "source": [
        "# load data\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Lw_bPQKQFX"
      },
      "source": [
        "## View the shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueyWl-aUmP72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d278a6c-25ba-4cfb-c169-3b54d902708b"
      },
      "source": [
        "print('Training data shape : ', X_train.shape, Y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape :  (60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bsoluyzBOYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf76a37-3bb7-4fa9-c051-59dd82ca8cdc"
      },
      "source": [
        "print('Testing data shape : ', X_test.shape, Y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data shape :  (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z51sdOntmP78"
      },
      "source": [
        "## Find the unique numbers from the train labels\n",
        "\n",
        "From what we see below, we don't need to worry about label encoding as all the classes are integer values from 0 to 9 with no gaps between the values. Given that we have 10 classes, what does this tell us about the last layer in our network?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o29O_gUTmP79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42992713-a074-4ea7-c731-3b8a2ffa911b"
      },
      "source": [
        "classes = np.unique(Y_train)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of outputs :  10\n",
            "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMMjLgbimP8B"
      },
      "source": [
        "## Plot some of the data\n",
        "\n",
        "You can change the value of ```data_point``` to explore different images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQpW4rajmP8C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "50390834-372f-40ae-82e5-c73054159248"
      },
      "source": [
        "data_point = 15\n",
        "\n",
        "plt.figure(figsize=[10,5])\n",
        " \n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(X_train[data_point,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(Y_train[data_point]))\n",
        " \n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(X_test[data_point,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(Y_test[data_point]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ground Truth : 1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_mGK_NVHwn"
      },
      "source": [
        "## Reshape needed\n",
        "\n",
        "Tensorflow wants to know the depth of an image. API https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "For CNNS, Tensorflow wants the format of the data as follows: [batches, rows, columns, depth]. \n",
        "\n",
        "In this case the colour channel/depth of the images is 1. Currently the shape is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBbn1qONB0M8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a1855e-ea7c-4366-d4ae-d9f7a68d94ef"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55ZpEbCB6kQ"
      },
      "source": [
        "We have a width of 28 and a height of 28 but no depth. So we can reshape it to include a value of one using the Numpy reshape function. Documentation https://numpy.org/doc/stable/reference/generated/numpy.reshape.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8HTp2YHVH4_"
      },
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
        "\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lQP7CElWVfe"
      },
      "source": [
        "## View the shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QKOvMPaWVfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bb36cc-c55a-415d-f2ce-626698241979"
      },
      "source": [
        "print('Training data shape : ', X_train.shape, Y_train.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape :  (60000, 28, 28, 1) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzGxSUONCRb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015c5471-2e02-4045-ac08-1fb526f4cd70"
      },
      "source": [
        "print('Testing data shape : ', X_test.shape, Y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing data shape :  (10000, 28, 28, 1) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyXyan4NCnVL"
      },
      "source": [
        "## Take a look at a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNkeCMoUmP8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2f0e03-eca2-4012-de29-a20f3eb237cd"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 13],\n",
              "        [ 73],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  4],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  1],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  3],\n",
              "        [  0],\n",
              "        [ 36],\n",
              "        [136],\n",
              "        [127],\n",
              "        [ 62],\n",
              "        [ 54],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  3],\n",
              "        [  4],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  3]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  6],\n",
              "        [  0],\n",
              "        [102],\n",
              "        [204],\n",
              "        [176],\n",
              "        [134],\n",
              "        [144],\n",
              "        [123],\n",
              "        [ 23],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 12],\n",
              "        [ 10],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [155],\n",
              "        [236],\n",
              "        [207],\n",
              "        [178],\n",
              "        [107],\n",
              "        [156],\n",
              "        [161],\n",
              "        [109],\n",
              "        [ 64],\n",
              "        [ 23],\n",
              "        [ 77],\n",
              "        [130],\n",
              "        [ 72],\n",
              "        [ 15]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  0],\n",
              "        [ 69],\n",
              "        [207],\n",
              "        [223],\n",
              "        [218],\n",
              "        [216],\n",
              "        [216],\n",
              "        [163],\n",
              "        [127],\n",
              "        [121],\n",
              "        [122],\n",
              "        [146],\n",
              "        [141],\n",
              "        [ 88],\n",
              "        [172],\n",
              "        [ 66]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  1],\n",
              "        [  1],\n",
              "        [  0],\n",
              "        [200],\n",
              "        [232],\n",
              "        [232],\n",
              "        [233],\n",
              "        [229],\n",
              "        [223],\n",
              "        [223],\n",
              "        [215],\n",
              "        [213],\n",
              "        [164],\n",
              "        [127],\n",
              "        [123],\n",
              "        [196],\n",
              "        [229],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [183],\n",
              "        [225],\n",
              "        [216],\n",
              "        [223],\n",
              "        [228],\n",
              "        [235],\n",
              "        [227],\n",
              "        [224],\n",
              "        [222],\n",
              "        [224],\n",
              "        [221],\n",
              "        [223],\n",
              "        [245],\n",
              "        [173],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [193],\n",
              "        [228],\n",
              "        [218],\n",
              "        [213],\n",
              "        [198],\n",
              "        [180],\n",
              "        [212],\n",
              "        [210],\n",
              "        [211],\n",
              "        [213],\n",
              "        [223],\n",
              "        [220],\n",
              "        [243],\n",
              "        [202],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  3],\n",
              "        [  0],\n",
              "        [ 12],\n",
              "        [219],\n",
              "        [220],\n",
              "        [212],\n",
              "        [218],\n",
              "        [192],\n",
              "        [169],\n",
              "        [227],\n",
              "        [208],\n",
              "        [218],\n",
              "        [224],\n",
              "        [212],\n",
              "        [226],\n",
              "        [197],\n",
              "        [209],\n",
              "        [ 52]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  6],\n",
              "        [  0],\n",
              "        [ 99],\n",
              "        [244],\n",
              "        [222],\n",
              "        [220],\n",
              "        [218],\n",
              "        [203],\n",
              "        [198],\n",
              "        [221],\n",
              "        [215],\n",
              "        [213],\n",
              "        [222],\n",
              "        [220],\n",
              "        [245],\n",
              "        [119],\n",
              "        [167],\n",
              "        [ 56]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  4],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 55],\n",
              "        [236],\n",
              "        [228],\n",
              "        [230],\n",
              "        [228],\n",
              "        [240],\n",
              "        [232],\n",
              "        [213],\n",
              "        [218],\n",
              "        [223],\n",
              "        [234],\n",
              "        [217],\n",
              "        [217],\n",
              "        [209],\n",
              "        [ 92],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  1],\n",
              "        [  4],\n",
              "        [  6],\n",
              "        [  7],\n",
              "        [  2],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [237],\n",
              "        [226],\n",
              "        [217],\n",
              "        [223],\n",
              "        [222],\n",
              "        [219],\n",
              "        [222],\n",
              "        [221],\n",
              "        [216],\n",
              "        [223],\n",
              "        [229],\n",
              "        [215],\n",
              "        [218],\n",
              "        [255],\n",
              "        [ 77],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  3],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 62],\n",
              "        [145],\n",
              "        [204],\n",
              "        [228],\n",
              "        [207],\n",
              "        [213],\n",
              "        [221],\n",
              "        [218],\n",
              "        [208],\n",
              "        [211],\n",
              "        [218],\n",
              "        [224],\n",
              "        [223],\n",
              "        [219],\n",
              "        [215],\n",
              "        [224],\n",
              "        [244],\n",
              "        [159],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 18],\n",
              "        [ 44],\n",
              "        [ 82],\n",
              "        [107],\n",
              "        [189],\n",
              "        [228],\n",
              "        [220],\n",
              "        [222],\n",
              "        [217],\n",
              "        [226],\n",
              "        [200],\n",
              "        [205],\n",
              "        [211],\n",
              "        [230],\n",
              "        [224],\n",
              "        [234],\n",
              "        [176],\n",
              "        [188],\n",
              "        [250],\n",
              "        [248],\n",
              "        [233],\n",
              "        [238],\n",
              "        [215],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [ 57],\n",
              "        [187],\n",
              "        [208],\n",
              "        [224],\n",
              "        [221],\n",
              "        [224],\n",
              "        [208],\n",
              "        [204],\n",
              "        [214],\n",
              "        [208],\n",
              "        [209],\n",
              "        [200],\n",
              "        [159],\n",
              "        [245],\n",
              "        [193],\n",
              "        [206],\n",
              "        [223],\n",
              "        [255],\n",
              "        [255],\n",
              "        [221],\n",
              "        [234],\n",
              "        [221],\n",
              "        [211],\n",
              "        [220],\n",
              "        [232],\n",
              "        [246],\n",
              "        [  0]],\n",
              "\n",
              "       [[  3],\n",
              "        [202],\n",
              "        [228],\n",
              "        [224],\n",
              "        [221],\n",
              "        [211],\n",
              "        [211],\n",
              "        [214],\n",
              "        [205],\n",
              "        [205],\n",
              "        [205],\n",
              "        [220],\n",
              "        [240],\n",
              "        [ 80],\n",
              "        [150],\n",
              "        [255],\n",
              "        [229],\n",
              "        [221],\n",
              "        [188],\n",
              "        [154],\n",
              "        [191],\n",
              "        [210],\n",
              "        [204],\n",
              "        [209],\n",
              "        [222],\n",
              "        [228],\n",
              "        [225],\n",
              "        [  0]],\n",
              "\n",
              "       [[ 98],\n",
              "        [233],\n",
              "        [198],\n",
              "        [210],\n",
              "        [222],\n",
              "        [229],\n",
              "        [229],\n",
              "        [234],\n",
              "        [249],\n",
              "        [220],\n",
              "        [194],\n",
              "        [215],\n",
              "        [217],\n",
              "        [241],\n",
              "        [ 65],\n",
              "        [ 73],\n",
              "        [106],\n",
              "        [117],\n",
              "        [168],\n",
              "        [219],\n",
              "        [221],\n",
              "        [215],\n",
              "        [217],\n",
              "        [223],\n",
              "        [223],\n",
              "        [224],\n",
              "        [229],\n",
              "        [ 29]],\n",
              "\n",
              "       [[ 75],\n",
              "        [204],\n",
              "        [212],\n",
              "        [204],\n",
              "        [193],\n",
              "        [205],\n",
              "        [211],\n",
              "        [225],\n",
              "        [216],\n",
              "        [185],\n",
              "        [197],\n",
              "        [206],\n",
              "        [198],\n",
              "        [213],\n",
              "        [240],\n",
              "        [195],\n",
              "        [227],\n",
              "        [245],\n",
              "        [239],\n",
              "        [223],\n",
              "        [218],\n",
              "        [212],\n",
              "        [209],\n",
              "        [222],\n",
              "        [220],\n",
              "        [221],\n",
              "        [230],\n",
              "        [ 67]],\n",
              "\n",
              "       [[ 48],\n",
              "        [203],\n",
              "        [183],\n",
              "        [194],\n",
              "        [213],\n",
              "        [197],\n",
              "        [185],\n",
              "        [190],\n",
              "        [194],\n",
              "        [192],\n",
              "        [202],\n",
              "        [214],\n",
              "        [219],\n",
              "        [221],\n",
              "        [220],\n",
              "        [236],\n",
              "        [225],\n",
              "        [216],\n",
              "        [199],\n",
              "        [206],\n",
              "        [186],\n",
              "        [181],\n",
              "        [177],\n",
              "        [172],\n",
              "        [181],\n",
              "        [205],\n",
              "        [206],\n",
              "        [115]],\n",
              "\n",
              "       [[  0],\n",
              "        [122],\n",
              "        [219],\n",
              "        [193],\n",
              "        [179],\n",
              "        [171],\n",
              "        [183],\n",
              "        [196],\n",
              "        [204],\n",
              "        [210],\n",
              "        [213],\n",
              "        [207],\n",
              "        [211],\n",
              "        [210],\n",
              "        [200],\n",
              "        [196],\n",
              "        [194],\n",
              "        [191],\n",
              "        [195],\n",
              "        [191],\n",
              "        [198],\n",
              "        [192],\n",
              "        [176],\n",
              "        [156],\n",
              "        [167],\n",
              "        [177],\n",
              "        [210],\n",
              "        [ 92]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [ 74],\n",
              "        [189],\n",
              "        [212],\n",
              "        [191],\n",
              "        [175],\n",
              "        [172],\n",
              "        [175],\n",
              "        [181],\n",
              "        [185],\n",
              "        [188],\n",
              "        [189],\n",
              "        [188],\n",
              "        [193],\n",
              "        [198],\n",
              "        [204],\n",
              "        [209],\n",
              "        [210],\n",
              "        [210],\n",
              "        [211],\n",
              "        [188],\n",
              "        [188],\n",
              "        [194],\n",
              "        [192],\n",
              "        [216],\n",
              "        [170],\n",
              "        [  0]],\n",
              "\n",
              "       [[  2],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 66],\n",
              "        [200],\n",
              "        [222],\n",
              "        [237],\n",
              "        [239],\n",
              "        [242],\n",
              "        [246],\n",
              "        [243],\n",
              "        [244],\n",
              "        [221],\n",
              "        [220],\n",
              "        [193],\n",
              "        [191],\n",
              "        [179],\n",
              "        [182],\n",
              "        [182],\n",
              "        [181],\n",
              "        [176],\n",
              "        [166],\n",
              "        [168],\n",
              "        [ 99],\n",
              "        [ 58],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [ 40],\n",
              "        [ 61],\n",
              "        [ 44],\n",
              "        [ 72],\n",
              "        [ 41],\n",
              "        [ 35],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]],\n",
              "\n",
              "       [[  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0],\n",
              "        [  0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fgq-DPpDY0y"
      },
      "source": [
        "## What is the min/max for this image?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk9fC6JDDUp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58063365-73ad-4cb2-98aa-126baf98091c"
      },
      "source": [
        "np.max(X_train[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciTWCBVjDXL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5744ef7-e4db-4e7a-b08f-19cffabf45f2"
      },
      "source": [
        "np.min(X_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BykRwF2UmP8b"
      },
      "source": [
        "## Normalise\n",
        "\n",
        "We need to normalise the data since the values range from 0 to 255. Training NNs on data ranging between [0,1] is recommended.\n",
        "\n",
        "Need to normalise all features, including training, validation and testing. We also need to apply the same normalisation to any new data (obtained in the future)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH2lcHF3mP8c"
      },
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXCZiTPZDB3d"
      },
      "source": [
        "## Take a look at a single image (after normalisation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRTTJ4kDDB_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f092cd12-81b4-4ad6-add9-be219eb3cec9"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.05098039],\n",
              "        [0.28627451],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.01568627],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.00392157],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.01176471],\n",
              "        [0.        ],\n",
              "        [0.14117647],\n",
              "        [0.53333333],\n",
              "        [0.49803922],\n",
              "        [0.24313725],\n",
              "        [0.21176471],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.01176471],\n",
              "        [0.01568627],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.01176471]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.02352941],\n",
              "        [0.        ],\n",
              "        [0.4       ],\n",
              "        [0.8       ],\n",
              "        [0.69019608],\n",
              "        [0.5254902 ],\n",
              "        [0.56470588],\n",
              "        [0.48235294],\n",
              "        [0.09019608],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.04705882],\n",
              "        [0.03921569],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.60784314],\n",
              "        [0.9254902 ],\n",
              "        [0.81176471],\n",
              "        [0.69803922],\n",
              "        [0.41960784],\n",
              "        [0.61176471],\n",
              "        [0.63137255],\n",
              "        [0.42745098],\n",
              "        [0.25098039],\n",
              "        [0.09019608],\n",
              "        [0.30196078],\n",
              "        [0.50980392],\n",
              "        [0.28235294],\n",
              "        [0.05882353]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.        ],\n",
              "        [0.27058824],\n",
              "        [0.81176471],\n",
              "        [0.8745098 ],\n",
              "        [0.85490196],\n",
              "        [0.84705882],\n",
              "        [0.84705882],\n",
              "        [0.63921569],\n",
              "        [0.49803922],\n",
              "        [0.4745098 ],\n",
              "        [0.47843137],\n",
              "        [0.57254902],\n",
              "        [0.55294118],\n",
              "        [0.34509804],\n",
              "        [0.6745098 ],\n",
              "        [0.25882353]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.00392157],\n",
              "        [0.00392157],\n",
              "        [0.        ],\n",
              "        [0.78431373],\n",
              "        [0.90980392],\n",
              "        [0.90980392],\n",
              "        [0.91372549],\n",
              "        [0.89803922],\n",
              "        [0.8745098 ],\n",
              "        [0.8745098 ],\n",
              "        [0.84313725],\n",
              "        [0.83529412],\n",
              "        [0.64313725],\n",
              "        [0.49803922],\n",
              "        [0.48235294],\n",
              "        [0.76862745],\n",
              "        [0.89803922],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.71764706],\n",
              "        [0.88235294],\n",
              "        [0.84705882],\n",
              "        [0.8745098 ],\n",
              "        [0.89411765],\n",
              "        [0.92156863],\n",
              "        [0.89019608],\n",
              "        [0.87843137],\n",
              "        [0.87058824],\n",
              "        [0.87843137],\n",
              "        [0.86666667],\n",
              "        [0.8745098 ],\n",
              "        [0.96078431],\n",
              "        [0.67843137],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.75686275],\n",
              "        [0.89411765],\n",
              "        [0.85490196],\n",
              "        [0.83529412],\n",
              "        [0.77647059],\n",
              "        [0.70588235],\n",
              "        [0.83137255],\n",
              "        [0.82352941],\n",
              "        [0.82745098],\n",
              "        [0.83529412],\n",
              "        [0.8745098 ],\n",
              "        [0.8627451 ],\n",
              "        [0.95294118],\n",
              "        [0.79215686],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.01176471],\n",
              "        [0.        ],\n",
              "        [0.04705882],\n",
              "        [0.85882353],\n",
              "        [0.8627451 ],\n",
              "        [0.83137255],\n",
              "        [0.85490196],\n",
              "        [0.75294118],\n",
              "        [0.6627451 ],\n",
              "        [0.89019608],\n",
              "        [0.81568627],\n",
              "        [0.85490196],\n",
              "        [0.87843137],\n",
              "        [0.83137255],\n",
              "        [0.88627451],\n",
              "        [0.77254902],\n",
              "        [0.81960784],\n",
              "        [0.20392157]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.02352941],\n",
              "        [0.        ],\n",
              "        [0.38823529],\n",
              "        [0.95686275],\n",
              "        [0.87058824],\n",
              "        [0.8627451 ],\n",
              "        [0.85490196],\n",
              "        [0.79607843],\n",
              "        [0.77647059],\n",
              "        [0.86666667],\n",
              "        [0.84313725],\n",
              "        [0.83529412],\n",
              "        [0.87058824],\n",
              "        [0.8627451 ],\n",
              "        [0.96078431],\n",
              "        [0.46666667],\n",
              "        [0.65490196],\n",
              "        [0.21960784]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.01568627],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.21568627],\n",
              "        [0.9254902 ],\n",
              "        [0.89411765],\n",
              "        [0.90196078],\n",
              "        [0.89411765],\n",
              "        [0.94117647],\n",
              "        [0.90980392],\n",
              "        [0.83529412],\n",
              "        [0.85490196],\n",
              "        [0.8745098 ],\n",
              "        [0.91764706],\n",
              "        [0.85098039],\n",
              "        [0.85098039],\n",
              "        [0.81960784],\n",
              "        [0.36078431],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.00392157],\n",
              "        [0.01568627],\n",
              "        [0.02352941],\n",
              "        [0.02745098],\n",
              "        [0.00784314],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.92941176],\n",
              "        [0.88627451],\n",
              "        [0.85098039],\n",
              "        [0.8745098 ],\n",
              "        [0.87058824],\n",
              "        [0.85882353],\n",
              "        [0.87058824],\n",
              "        [0.86666667],\n",
              "        [0.84705882],\n",
              "        [0.8745098 ],\n",
              "        [0.89803922],\n",
              "        [0.84313725],\n",
              "        [0.85490196],\n",
              "        [1.        ],\n",
              "        [0.30196078],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.01176471],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.24313725],\n",
              "        [0.56862745],\n",
              "        [0.8       ],\n",
              "        [0.89411765],\n",
              "        [0.81176471],\n",
              "        [0.83529412],\n",
              "        [0.86666667],\n",
              "        [0.85490196],\n",
              "        [0.81568627],\n",
              "        [0.82745098],\n",
              "        [0.85490196],\n",
              "        [0.87843137],\n",
              "        [0.8745098 ],\n",
              "        [0.85882353],\n",
              "        [0.84313725],\n",
              "        [0.87843137],\n",
              "        [0.95686275],\n",
              "        [0.62352941],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.07058824],\n",
              "        [0.17254902],\n",
              "        [0.32156863],\n",
              "        [0.41960784],\n",
              "        [0.74117647],\n",
              "        [0.89411765],\n",
              "        [0.8627451 ],\n",
              "        [0.87058824],\n",
              "        [0.85098039],\n",
              "        [0.88627451],\n",
              "        [0.78431373],\n",
              "        [0.80392157],\n",
              "        [0.82745098],\n",
              "        [0.90196078],\n",
              "        [0.87843137],\n",
              "        [0.91764706],\n",
              "        [0.69019608],\n",
              "        [0.7372549 ],\n",
              "        [0.98039216],\n",
              "        [0.97254902],\n",
              "        [0.91372549],\n",
              "        [0.93333333],\n",
              "        [0.84313725],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.22352941],\n",
              "        [0.73333333],\n",
              "        [0.81568627],\n",
              "        [0.87843137],\n",
              "        [0.86666667],\n",
              "        [0.87843137],\n",
              "        [0.81568627],\n",
              "        [0.8       ],\n",
              "        [0.83921569],\n",
              "        [0.81568627],\n",
              "        [0.81960784],\n",
              "        [0.78431373],\n",
              "        [0.62352941],\n",
              "        [0.96078431],\n",
              "        [0.75686275],\n",
              "        [0.80784314],\n",
              "        [0.8745098 ],\n",
              "        [1.        ],\n",
              "        [1.        ],\n",
              "        [0.86666667],\n",
              "        [0.91764706],\n",
              "        [0.86666667],\n",
              "        [0.82745098],\n",
              "        [0.8627451 ],\n",
              "        [0.90980392],\n",
              "        [0.96470588],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.01176471],\n",
              "        [0.79215686],\n",
              "        [0.89411765],\n",
              "        [0.87843137],\n",
              "        [0.86666667],\n",
              "        [0.82745098],\n",
              "        [0.82745098],\n",
              "        [0.83921569],\n",
              "        [0.80392157],\n",
              "        [0.80392157],\n",
              "        [0.80392157],\n",
              "        [0.8627451 ],\n",
              "        [0.94117647],\n",
              "        [0.31372549],\n",
              "        [0.58823529],\n",
              "        [1.        ],\n",
              "        [0.89803922],\n",
              "        [0.86666667],\n",
              "        [0.7372549 ],\n",
              "        [0.60392157],\n",
              "        [0.74901961],\n",
              "        [0.82352941],\n",
              "        [0.8       ],\n",
              "        [0.81960784],\n",
              "        [0.87058824],\n",
              "        [0.89411765],\n",
              "        [0.88235294],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.38431373],\n",
              "        [0.91372549],\n",
              "        [0.77647059],\n",
              "        [0.82352941],\n",
              "        [0.87058824],\n",
              "        [0.89803922],\n",
              "        [0.89803922],\n",
              "        [0.91764706],\n",
              "        [0.97647059],\n",
              "        [0.8627451 ],\n",
              "        [0.76078431],\n",
              "        [0.84313725],\n",
              "        [0.85098039],\n",
              "        [0.94509804],\n",
              "        [0.25490196],\n",
              "        [0.28627451],\n",
              "        [0.41568627],\n",
              "        [0.45882353],\n",
              "        [0.65882353],\n",
              "        [0.85882353],\n",
              "        [0.86666667],\n",
              "        [0.84313725],\n",
              "        [0.85098039],\n",
              "        [0.8745098 ],\n",
              "        [0.8745098 ],\n",
              "        [0.87843137],\n",
              "        [0.89803922],\n",
              "        [0.11372549]],\n",
              "\n",
              "       [[0.29411765],\n",
              "        [0.8       ],\n",
              "        [0.83137255],\n",
              "        [0.8       ],\n",
              "        [0.75686275],\n",
              "        [0.80392157],\n",
              "        [0.82745098],\n",
              "        [0.88235294],\n",
              "        [0.84705882],\n",
              "        [0.7254902 ],\n",
              "        [0.77254902],\n",
              "        [0.80784314],\n",
              "        [0.77647059],\n",
              "        [0.83529412],\n",
              "        [0.94117647],\n",
              "        [0.76470588],\n",
              "        [0.89019608],\n",
              "        [0.96078431],\n",
              "        [0.9372549 ],\n",
              "        [0.8745098 ],\n",
              "        [0.85490196],\n",
              "        [0.83137255],\n",
              "        [0.81960784],\n",
              "        [0.87058824],\n",
              "        [0.8627451 ],\n",
              "        [0.86666667],\n",
              "        [0.90196078],\n",
              "        [0.2627451 ]],\n",
              "\n",
              "       [[0.18823529],\n",
              "        [0.79607843],\n",
              "        [0.71764706],\n",
              "        [0.76078431],\n",
              "        [0.83529412],\n",
              "        [0.77254902],\n",
              "        [0.7254902 ],\n",
              "        [0.74509804],\n",
              "        [0.76078431],\n",
              "        [0.75294118],\n",
              "        [0.79215686],\n",
              "        [0.83921569],\n",
              "        [0.85882353],\n",
              "        [0.86666667],\n",
              "        [0.8627451 ],\n",
              "        [0.9254902 ],\n",
              "        [0.88235294],\n",
              "        [0.84705882],\n",
              "        [0.78039216],\n",
              "        [0.80784314],\n",
              "        [0.72941176],\n",
              "        [0.70980392],\n",
              "        [0.69411765],\n",
              "        [0.6745098 ],\n",
              "        [0.70980392],\n",
              "        [0.80392157],\n",
              "        [0.80784314],\n",
              "        [0.45098039]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.47843137],\n",
              "        [0.85882353],\n",
              "        [0.75686275],\n",
              "        [0.70196078],\n",
              "        [0.67058824],\n",
              "        [0.71764706],\n",
              "        [0.76862745],\n",
              "        [0.8       ],\n",
              "        [0.82352941],\n",
              "        [0.83529412],\n",
              "        [0.81176471],\n",
              "        [0.82745098],\n",
              "        [0.82352941],\n",
              "        [0.78431373],\n",
              "        [0.76862745],\n",
              "        [0.76078431],\n",
              "        [0.74901961],\n",
              "        [0.76470588],\n",
              "        [0.74901961],\n",
              "        [0.77647059],\n",
              "        [0.75294118],\n",
              "        [0.69019608],\n",
              "        [0.61176471],\n",
              "        [0.65490196],\n",
              "        [0.69411765],\n",
              "        [0.82352941],\n",
              "        [0.36078431]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.29019608],\n",
              "        [0.74117647],\n",
              "        [0.83137255],\n",
              "        [0.74901961],\n",
              "        [0.68627451],\n",
              "        [0.6745098 ],\n",
              "        [0.68627451],\n",
              "        [0.70980392],\n",
              "        [0.7254902 ],\n",
              "        [0.7372549 ],\n",
              "        [0.74117647],\n",
              "        [0.7372549 ],\n",
              "        [0.75686275],\n",
              "        [0.77647059],\n",
              "        [0.8       ],\n",
              "        [0.81960784],\n",
              "        [0.82352941],\n",
              "        [0.82352941],\n",
              "        [0.82745098],\n",
              "        [0.7372549 ],\n",
              "        [0.7372549 ],\n",
              "        [0.76078431],\n",
              "        [0.75294118],\n",
              "        [0.84705882],\n",
              "        [0.66666667],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.00784314],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.25882353],\n",
              "        [0.78431373],\n",
              "        [0.87058824],\n",
              "        [0.92941176],\n",
              "        [0.9372549 ],\n",
              "        [0.94901961],\n",
              "        [0.96470588],\n",
              "        [0.95294118],\n",
              "        [0.95686275],\n",
              "        [0.86666667],\n",
              "        [0.8627451 ],\n",
              "        [0.75686275],\n",
              "        [0.74901961],\n",
              "        [0.70196078],\n",
              "        [0.71372549],\n",
              "        [0.71372549],\n",
              "        [0.70980392],\n",
              "        [0.69019608],\n",
              "        [0.65098039],\n",
              "        [0.65882353],\n",
              "        [0.38823529],\n",
              "        [0.22745098],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.15686275],\n",
              "        [0.23921569],\n",
              "        [0.17254902],\n",
              "        [0.28235294],\n",
              "        [0.16078431],\n",
              "        [0.1372549 ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]],\n",
              "\n",
              "       [[0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.        ]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzew90mNDdoJ"
      },
      "source": [
        "## What is the min/max for this image after normalisation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzGZPbxvDdoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06d0246-b47e-4011-fe07-219e035b089f"
      },
      "source": [
        "np.max(X_train[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGkND0LVDdoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0df64e8-5a1d-4230-9af3-82eb29d51b53"
      },
      "source": [
        "np.min(X_train[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj0QhPSsmP8e"
      },
      "source": [
        "## One hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGRXrRTYmP8g"
      },
      "source": [
        "## Before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrKyI7DamP8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff21b621-ad0d-4984-d2e0-26d7bec99991"
      },
      "source": [
        "Y_test[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfClFp-6K7P6"
      },
      "source": [
        "## Convert from categorical labels to one-hot encoded vectors\n",
        "\n",
        "In this case there are 10 classes so we can tell the function to convert into a vector of length 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3xjsPnVmP8j"
      },
      "source": [
        "Y_train = np_utils.to_categorical(Y_train, 10)\n",
        "Y_test = np_utils.to_categorical(Y_test, 10)\n",
        "num_classes = 10"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92H9U6LkmP8m"
      },
      "source": [
        "## After"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiiXZrnUmP8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c80548-d4e3-4c7e-9c5b-1ff196cc13e7"
      },
      "source": [
        "Y_test[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VungsdeHmP8u"
      },
      "source": [
        "## Create a CNN model\n",
        "\n",
        "A lot of things here are not new. \n",
        "\n",
        "Creating a sequential model is not new.\n",
        "\n",
        "Dropout is not new\n",
        "\n",
        "Creating a fully connected layer is not new.\n",
        "\n",
        "Creating a softmax output is not new.\n",
        "\n",
        "What's new is: Conv2D, MaxPooling2D and Flatten\n",
        "\n",
        "Documentation:\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gozmsPxhmP8v"
      },
      "source": [
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Since this is the first layer, we need to specify the input shape. Only here, only once.\n",
        "    # We are creating 64 filters each of size 2x2. What will be the depth of each of those 64 filters?\n",
        "    # What will be the resulting depth of the feature map after applying these filters?\n",
        "\n",
        "    # \"valid\" means no padding. \"same\" results in padding with zeros evenly to the \n",
        "    # left/right or up/down of the input such that output has the same height/width dimension as the input. \n",
        "    model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) ##padding=same is to preserve the dimension\n",
        "    \n",
        "    # Here we create a 2x2 max pooling layer\n",
        "    model.add(MaxPool2D(pool_size=2))\n",
        "    \n",
        "    # In order to pass output from the convolutional block to the dense block, we must flatten each example in the minibatch. \n",
        "    # In other words, we take this four-dimensional input [batch, width, height, depth] and transform it into the two-dimensional input [batch, units/input dimensions] expected by fully-connected layers\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    optimizer = SGD(learning_rate=0.9)\n",
        "    loss = CategoricalCrossentropy()\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(loss=loss,\n",
        "             optimizer=optimizer,\n",
        "             metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q03EcUrxmP8x"
      },
      "source": [
        "model = baseline_model()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiqw6XFAeWgs"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfTzqjKZeWi1"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TvGlRAceWmN"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUN6K31smP80"
      },
      "source": [
        "## Determine the number of trainable parameters\n",
        "\n",
        "Look at how many parameters we get from the last layer in the feature extractor to the first fully connected layer in the classifier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxDanOHmP80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1723618d-2a16-44b9-f93e-21224924491f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 128)       640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1605696   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 1,608,746\n",
            "Trainable params: 1,608,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppxTtRIfBUgr"
      },
      "source": [
        "Now let's do something new. Let's save the model weights while training and keep track of the best model on the validation accuracy.\n",
        "\n",
        "API for saving checkpoints https://www.tensorflow.org/tutorials/keras/save_and_load and https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
        "\n",
        "Additional things like the ability to determine the latest checkpoint exists: `tf.train.latest_checkpoint`. Take a look at the documentation for more interesting things."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBQfomgaBUo3"
      },
      "source": [
        "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
        "\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                              save_best_only=True, \n",
        "                              save_weights_only=True, \n",
        "                              verbose=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifPs0mftmP84"
      },
      "source": [
        "## Begin training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8RZc1rhmP84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2a3a50-bed3-40e0-af09-52a136c605cf"
      },
      "source": [
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=256, verbose=1, callbacks=[cp_callback])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 34s 14ms/step - loss: 1.2141 - accuracy: 0.5474 - val_loss: 0.6686 - val_accuracy: 0.7345\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.66859, saving model to training/cp-0001.ckpt\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.6805 - accuracy: 0.7607 - val_loss: 0.5001 - val_accuracy: 0.8286\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.66859 to 0.50011, saving model to training/cp-0002.ckpt\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.6117 - accuracy: 0.7893 - val_loss: 0.4504 - val_accuracy: 0.8371\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.50011 to 0.45037, saving model to training/cp-0003.ckpt\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.5768 - accuracy: 0.8025 - val_loss: 0.4578 - val_accuracy: 0.8357\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.45037\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.5565 - accuracy: 0.8109 - val_loss: 0.4368 - val_accuracy: 0.8429\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.45037 to 0.43676, saving model to training/cp-0005.ckpt\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.5354 - accuracy: 0.8188 - val_loss: 0.4413 - val_accuracy: 0.8373\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.43676\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.5162 - accuracy: 0.8251 - val_loss: 0.4108 - val_accuracy: 0.8453\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.43676 to 0.41080, saving model to training/cp-0007.ckpt\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.5131 - accuracy: 0.8281 - val_loss: 0.4039 - val_accuracy: 0.8554\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.41080 to 0.40387, saving model to training/cp-0008.ckpt\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.4991 - accuracy: 0.8298 - val_loss: 0.3978 - val_accuracy: 0.8488\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.40387 to 0.39778, saving model to training/cp-0009.ckpt\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.4855 - accuracy: 0.8349 - val_loss: 0.3917 - val_accuracy: 0.8614\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.39778 to 0.39172, saving model to training/cp-0010.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6e203dfad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KRrCPwmCtkP"
      },
      "source": [
        "Check on the left using the `file` option. You'll see a new folder and the checkpoints saved. Next let's get the correct testing values and then compare the predictions on the test data when initialising the model as opposed to loading the best weights from training and predicting again on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taRru5jrHm8P"
      },
      "source": [
        "correct_values = np.argmax(Y_test,axis=1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glts9LxlHeF_",
        "outputId": "9ecd647c-fca4-4ff6-bbd5-de07f7563712"
      },
      "source": [
        "model = baseline_model()\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "accuracy_score(predictions,correct_values)*100"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xaayowmlHVK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrYa0jqFCtuO",
        "outputId": "5f3514cf-729e-4343-9cf9-d4a4239bd087"
      },
      "source": [
        "model = baseline_model()\n",
        "model.load_weights(\"training/cp-0008.ckpt\")\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "accuracy_score(predictions,correct_values)*100"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9do3Cl8vmP87"
      },
      "source": [
        "## Predict on one example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnI4SnbEmP88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49ba700d-8166-47ce-a0a5-e4f94a3f50ca"
      },
      "source": [
        "model.predict(np.expand_dims(X_test[0], axis=0))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.7750616e-07, 1.2882975e-05, 3.5381740e-07, 5.0055942e-06,\n",
              "        6.8049684e-07, 4.9995789e-03, 1.3508976e-06, 3.6067292e-02,\n",
              "        1.8318897e-04, 9.5872885e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW3HNzapEV47"
      },
      "source": [
        "## Predicting, but obtaining the probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80LVXvFkEWEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56506e25-2750-43a7-b9ab-2efc519781eb"
      },
      "source": [
        "prediction = model.predict(np.expand_dims(X_test[0], axis=0))\n",
        "np.argmax(prediction, axis=-1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j9LecHgmP8_"
      },
      "source": [
        "## Predict on all the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TtfkDWjmP8_"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions = np.argmax(predictions, axis=-1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBmZspLUmP9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdcff8af-d098-4982-f448-1064bb90db38"
      },
      "source": [
        "predictions[0:10]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKy0gGBhE2gX"
      },
      "source": [
        "Before applying the `accuracy_score` function we need to conver the data into single class integers. In it's current form, the Y_test values aren't suitable. To address this, we can use the `np.argmax` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJiTOY3aWjcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12167b4-dee4-4659-88cd-2d91cb94025e"
      },
      "source": [
        "confusion_matrix(predictions,correct_values)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[853,   0,  16,  20,   0,   0, 232,   0,   1,   0],\n",
              "       [  0, 955,   0,   1,   1,   0,   0,   0,   0,   0],\n",
              "       [ 16,   0, 886,   9, 221,   0, 132,   0,   0,   0],\n",
              "       [ 40,  32,   8, 927,  48,   0,  37,   0,   7,   0],\n",
              "       [  1,   1,  22,   8, 539,   0,  31,   0,   0,   0],\n",
              "       [  2,   1,   0,   0,   0, 972,   0,  20,   4,  13],\n",
              "       [ 74,   8,  64,  28, 184,   1, 545,   0,   8,   0],\n",
              "       [  0,   0,   0,   0,   0,  23,   0, 948,   2,  35],\n",
              "       [ 14,   3,   4,   7,   7,   1,  23,   1, 978,   1],\n",
              "       [  0,   0,   0,   0,   0,   3,   0,  31,   0, 951]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEdkE4j--VzR"
      },
      "source": [
        "# Task:\n",
        "\n",
        "1) Add another convolutional layer to the current model.\n",
        "\n",
        "2) Add another max pooling layer to the current model.\n",
        "\n",
        "3) Modify the network and try improve your performance by using different architectures and hyper-parameters.\n",
        "\n",
        "4) Replace the max pooling with average pooling\n",
        "\n",
        "5) Add a stride of 2 to your average pooling layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSKtAYriFQLO"
      },
      "source": [
        "def baseline_model_1():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Since this is the first layer, we need to specify the input shape. Only here, only once.\n",
        "    # We are creating 64 filters each of size 2x2. What will be the depth of each of those 64 filters?\n",
        "    # What will be the resulting depth of the feature map after applying these filters?\n",
        "\n",
        "    # \"valid\" means no padding. \"same\" results in padding with zeros evenly to the \n",
        "    # left/right or up/down of the input such that output has the same height/width dimension as the input. \n",
        "    model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) ##padding=same is to preserve the dimension\n",
        "    \n",
        "    # Here we create a 2x2 max pooling layer\n",
        "    model.add(MaxPool2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=2,padding='same', strides=2,activation='relu'))\n",
        "    model.add(AveragePooling2D(pool_size=2))\n",
        "    \n",
        "    # In order to pass output from the convolutional block to the dense block, we must flatten each example in the minibatch. \n",
        "    # In other words, we take this four-dimensional input [batch, width, height, depth] and transform it into the two-dimensional input [batch, units/input dimensions] expected by fully-connected layers\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    optimizer = SGD(learning_rate=0.9)\n",
        "    loss = CategoricalCrossentropy()\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(loss=loss,\n",
        "             optimizer=optimizer,\n",
        "             metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCNjx9MeYvg"
      },
      "source": [
        "model1= baseline_model_1()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLuWsXwNeY1l",
        "outputId": "344cf5bb-926c-4448-8903-86f14537f32c"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 128)       640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 64)          32832     \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 72,810\n",
            "Trainable params: 72,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3FD65RJeo6g"
      },
      "source": [
        "# checkpoint_path1 = \"training/cp-{epoch:04d}.ckpt\"\n",
        "\n",
        "# cp_callback1 = ModelCheckpoint(filepath=checkpoint_path1, \n",
        "#                               save_best_only=True, \n",
        "#                               save_weights_only=True, \n",
        "#                               verbose=1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv99Ua2beo8q",
        "outputId": "34a2b9fc-a6e5-4d18-9cdc-4268444d75fb"
      },
      "source": [
        "model1.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=256, verbose=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 4s 14ms/step - loss: 1.6451 - accuracy: 0.3493 - val_loss: 0.9968 - val_accuracy: 0.6251\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.0872 - accuracy: 0.5730 - val_loss: 0.9832 - val_accuracy: 0.6483\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.9228 - accuracy: 0.6471 - val_loss: 0.6603 - val_accuracy: 0.7288\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.8221 - accuracy: 0.6939 - val_loss: 0.6820 - val_accuracy: 0.7170\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.7774 - accuracy: 0.7180 - val_loss: 0.7288 - val_accuracy: 0.6905\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.7392 - accuracy: 0.7346 - val_loss: 0.5667 - val_accuracy: 0.7840\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.7188 - accuracy: 0.7430 - val_loss: 0.6531 - val_accuracy: 0.7646\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.6990 - accuracy: 0.7520 - val_loss: 0.5173 - val_accuracy: 0.8041\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.6751 - accuracy: 0.7585 - val_loss: 0.5190 - val_accuracy: 0.8001\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.6793 - accuracy: 0.7573 - val_loss: 0.5257 - val_accuracy: 0.8041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6e201f3750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUPYVhd0eo_Q"
      },
      "source": [
        "correct_values = np.argmax(Y_test,axis=1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahqgTuSJepBT",
        "outputId": "1b1b50c8-0890-4851-bef0-6f00b44e8482"
      },
      "source": [
        "model = baseline_model_1()\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "accuracy_score(predictions,correct_values)*100"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DIDN3lvn_lC"
      },
      "source": [
        "# model = baseline_model_1()\n",
        "# model.load_weights(\"training/cp-0010.ckpt\")\n",
        "\n",
        "# predictions = model.predict(X_test)\n",
        "# predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# accuracy_score(predictions,correct_values)*100"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgO7aONWoIn8",
        "outputId": "912a650a-14d8-46f9-a72a-85906cd5d903"
      },
      "source": [
        "confusion_matrix(predictions,correct_values)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   5,   0,   0,   1,   0],\n",
              "       [ 15,   7,  13,   9,  14,   0,   8,   0,   4,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [982, 985, 986, 984, 979, 867, 989, 979, 875, 984],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   8,   0,   4,   4,  41,   1,   5,   1,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  3,   0,   1,   3,   3,  87,   2,  16, 119,  14],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}